{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f672e8",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook provides an initial exploration of the financial data to understand:\n",
    "- Data structure and quality\n",
    "- Basic statistics and distributions\n",
    "- Missing values and data types\n",
    "- Initial insights and patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19ef14",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Import project modules\n",
    "from src.data_processing.database_manager import DatabaseManager\n",
    "from src.data_processing.excel_importer import ExcelImporter\n",
    "from src.data_processing.data_cleaner import DataCleaner\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e9f19",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database manager\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "# Load financial data\n",
    "query = \"\"\"\n",
    "SELECT date, amount, category, subcategory, description, \n",
    "       store_location, payment_method, created_at\n",
    "FROM financial_data\n",
    "ORDER BY date DESC\n",
    "\"\"\"\n",
    "\n",
    "df = db_manager.query_data(query)\n",
    "print(f\"Loaded {len(df):,} records\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Convert date column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ff24b",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed004e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMemory Usage:\")\n",
    "print(f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing values\n",
    "if not missing_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_df['Missing Percentage'].plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Missing Values by Column')\n",
    "    ax.set_ylabel('Percentage Missing')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1478a5",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "print(\"Numerical Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Amount statistics\n",
    "print(\"\\nAmount Statistics:\")\n",
    "print(f\"Total Amount: ${df['amount'].sum():,.2f}\")\n",
    "print(f\"Mean Amount: ${df['amount'].mean():,.2f}\")\n",
    "print(f\"Median Amount: ${df['amount'].median():,.2f}\")\n",
    "print(f\"Standard Deviation: ${df['amount'].std():,.2f}\")\n",
    "print(f\"Min Amount: ${df['amount'].min():,.2f}\")\n",
    "print(f\"Max Amount: ${df['amount'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data analysis\n",
    "categorical_columns = ['category', 'subcategory', 'store_location', 'payment_method']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns and not df[col].isnull().all():\n",
    "        print(f\"\\n{col.replace('_', ' ').title()} Distribution:\")\n",
    "        value_counts = df[col].value_counts().head(10)\n",
    "        print(value_counts)\n",
    "        print(f\"Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ddb52",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c28b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(df['amount'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Amount Distribution')\n",
    "axes[0, 0].set_xlabel('Amount')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[0, 1].boxplot(df['amount'])\n",
    "axes[0, 1].set_title('Amount Box Plot')\n",
    "axes[0, 1].set_ylabel('Amount')\n",
    "\n",
    "# Log scale histogram (if positive values)\n",
    "positive_amounts = df[df['amount'] > 0]['amount']\n",
    "if len(positive_amounts) > 0:\n",
    "    axes[1, 0].hist(np.log10(positive_amounts), bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_title('Amount Distribution (Log Scale)')\n",
    "    axes[1, 0].set_xlabel('Log10(Amount)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Cumulative distribution\n",
    "sorted_amounts = np.sort(df['amount'])\n",
    "y = np.arange(1, len(sorted_amounts) + 1) / len(sorted_amounts)\n",
    "axes[1, 1].plot(sorted_amounts, y)\n",
    "axes[1, 1].set_title('Cumulative Distribution')\n",
    "axes[1, 1].set_xlabel('Amount')\n",
    "axes[1, 1].set_ylabel('Cumulative Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "# Daily aggregation\n",
    "daily_amounts = df.groupby(df['date'].dt.date)['amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "daily_amounts['date'] = pd.to_datetime(daily_amounts['date'])\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Daily total amounts\n",
    "axes[0].plot(daily_amounts['date'], daily_amounts['sum'])\n",
    "axes[0].set_title('Daily Total Amount')\n",
    "axes[0].set_ylabel('Total Amount')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Daily transaction count\n",
    "axes[1].plot(daily_amounts['date'], daily_amounts['count'], color='orange')\n",
    "axes[1].set_title('Daily Transaction Count')\n",
    "axes[1].set_ylabel('Number of Transactions')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Daily average amount\n",
    "axes[2].plot(daily_amounts['date'], daily_amounts['mean'], color='green')\n",
    "axes[2].set_title('Daily Average Transaction Amount')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_ylabel('Average Amount')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbf2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category analysis\n",
    "if 'category' in df.columns and not df['category'].isnull().all():\n",
    "    category_stats = df.groupby('category')['amount'].agg(['sum', 'count', 'mean']).sort_values('sum', ascending=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Total amount by category\n",
    "    top_categories = category_stats.head(10)\n",
    "    axes[0, 0].bar(range(len(top_categories)), top_categories['sum'])\n",
    "    axes[0, 0].set_title('Total Amount by Category (Top 10)')\n",
    "    axes[0, 0].set_ylabel('Total Amount')\n",
    "    axes[0, 0].set_xticks(range(len(top_categories)))\n",
    "    axes[0, 0].set_xticklabels(top_categories.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Transaction count by category\n",
    "    axes[0, 1].bar(range(len(top_categories)), top_categories['count'], color='orange')\n",
    "    axes[0, 1].set_title('Transaction Count by Category (Top 10)')\n",
    "    axes[0, 1].set_ylabel('Number of Transactions')\n",
    "    axes[0, 1].set_xticks(range(len(top_categories)))\n",
    "    axes[0, 1].set_xticklabels(top_categories.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Average amount by category\n",
    "    avg_sorted = category_stats.sort_values('mean', ascending=False).head(10)\n",
    "    axes[1, 0].bar(range(len(avg_sorted)), avg_sorted['mean'], color='green')\n",
    "    axes[1, 0].set_title('Average Amount by Category (Top 10)')\n",
    "    axes[1, 0].set_ylabel('Average Amount')\n",
    "    axes[1, 0].set_xticks(range(len(avg_sorted)))\n",
    "    axes[1, 0].set_xticklabels(avg_sorted.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Pie chart for top categories\n",
    "    top_5_categories = category_stats.head(5)\n",
    "    axes[1, 1].pie(top_5_categories['sum'], labels=top_5_categories.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Amount Distribution (Top 5 Categories)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCategory Statistics:\")\n",
    "    print(category_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff16d8",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data cleaner to assess quality\n",
    "cleaner = DataCleaner()\n",
    "quality_report = cleaner.validate_data_quality(df)\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "print(f\"Quality Score: {quality_report['quality_score']:.2f}/100\")\n",
    "print(f\"Total Rows: {quality_report['total_rows']:,}\")\n",
    "print(f\"Total Columns: {quality_report['total_columns']}\")\n",
    "print(f\"Duplicate Rows: {quality_report['duplicate_rows']:,}\")\n",
    "print(f\"Memory Usage: {quality_report['memory_usage'] / 1024**2:.2f} MB\")\n",
    "\n",
    "if quality_report['missing_required_columns']:\n",
    "    print(f\"Missing Required Columns: {quality_report['missing_required_columns']}\")\n",
    "else:\n",
    "    print(\"All required columns present\")\n",
    "\n",
    "print(\"\\nMissing Values by Column:\")\n",
    "for col, missing_count in quality_report['missing_values'].items():\n",
    "    if missing_count > 0:\n",
    "        percentage = (missing_count / quality_report['total_rows']) * 100\n",
    "        print(f\"  {col}: {missing_count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00d6a2",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d40b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "Q1 = df['amount'].quantile(0.25)\n",
    "Q3 = df['amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['amount'] < lower_bound) | (df['amount'] > upper_bound)]\n",
    "\n",
    "print(f\"Outlier Detection (IQR Method):\")\n",
    "print(f\"Lower Bound: ${lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: ${upper_bound:.2f}\")\n",
    "print(f\"Number of Outliers: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(f\"\\nOutlier Statistics:\")\n",
    "    print(f\"Min Outlier: ${outliers['amount'].min():.2f}\")\n",
    "    print(f\"Max Outlier: ${outliers['amount'].max():.2f}\")\n",
    "    print(f\"Mean Outlier: ${outliers['amount'].mean():.2f}\")\n",
    "    \n",
    "    # Show top 10 largest outliers\n",
    "    print(\"\\nTop 10 Largest Outliers:\")\n",
    "    top_outliers = outliers.nlargest(10, 'amount')[['date', 'amount', 'category', 'description']]\n",
    "    print(top_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8dde7",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numerical features for correlation analysis\n",
    "df_corr = df.copy()\n",
    "\n",
    "# Add time-based features\n",
    "df_corr['year'] = df_corr['date'].dt.year\n",
    "df_corr['month'] = df_corr['date'].dt.month\n",
    "df_corr['day_of_week'] = df_corr['date'].dt.dayofweek\n",
    "df_corr['day_of_month'] = df_corr['date'].dt.day\n",
    "df_corr['hour'] = df_corr['date'].dt.hour\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = df_corr.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_corr[numerical_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with amount\n",
    "if 'amount' in correlation_matrix.columns:\n",
    "    amount_correlations = correlation_matrix['amount'].abs().sort_values(ascending=False)\n",
    "    print(\"\\nCorrelations with Amount:\")\n",
    "    print(amount_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714f5f7",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Dataset Size: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "print(f\"Date Range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Total Amount: ${df['amount'].sum():,.2f}\")\n",
    "print(f\"Average Transaction: ${df['amount'].mean():.2f}\")\n",
    "print(f\"Data Quality Score: {quality_report['quality_score']:.1f}/100\")\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    print(f\"Number of Categories: {df['category'].nunique()}\")\n",
    "    print(f\"Top Category: {df.groupby('category')['amount'].sum().idxmax()}\")\n",
    "\n",
    "print(f\"Outliers Detected: {len(outliers):,} ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "missing_cols = [col for col, count in quality_report['missing_values'].items() if count > 0]\n",
    "if missing_cols:\n",
    "    print(f\"Columns with Missing Data: {', '.join(missing_cols)}\")\n",
    "else:\n",
    "    print(\"No missing data detected\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Review and clean any data quality issues\")\n",
    "print(\"2. Investigate outliers for validity\")\n",
    "print(\"3. Perform detailed financial analysis\")\n",
    "print(\"4. Analyze trends and patterns over time\")\n",
    "print(\"5. Build predictive models if needed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
