{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eead667",
   "metadata": {},
   "source": [
    "# Trend Analysis and Forecasting\n",
    "\n",
    "This notebook focuses on:\n",
    "- Time series trend analysis\n",
    "- Seasonal decomposition\n",
    "- Anomaly detection\n",
    "- Financial forecasting\n",
    "- Predictive modeling\n",
    "- Risk analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e67e5",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Import project modules\n",
    "from src.data_processing.database_manager import DatabaseManager\n",
    "from src.analysis.trend_analysis import TrendAnalyzer\n",
    "from src.analysis.financial_metrics import FinancialMetricsCalculator\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "db_manager = DatabaseManager()\n",
    "trend_analyzer = TrendAnalyzer()\n",
    "metrics_calculator = FinancialMetricsCalculator()\n",
    "\n",
    "# Load financial data\n",
    "query = \"\"\"\n",
    "SELECT date, amount, category, subcategory, description, \n",
    "       store_location, payment_method\n",
    "FROM financial_data\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "df = db_manager.query_data(query)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create time series data\n",
    "daily_data = df.groupby('date').agg({\n",
    "    'amount': ['sum', 'count', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "daily_data.columns = ['total_amount', 'transaction_count', 'avg_amount']\n",
    "daily_data = daily_data.reset_index()\n",
    "\n",
    "print(f\"Loaded {len(df):,} records\")\n",
    "print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Daily data points: {len(daily_data)}\")\n",
    "print(f\"Amount range: ${df['amount'].min():.2f} to ${df['amount'].max():.2f}\")\n",
    "\n",
    "# Display sample of daily data\n",
    "print(\"\\nDaily Data Sample:\")\n",
    "print(daily_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e7633",
   "metadata": {},
   "source": [
    "## Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69044f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive time series plots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Daily total amount\n",
    "axes[0].plot(daily_data['date'], daily_data['total_amount'], \n",
    "             linewidth=1, alpha=0.7, color='blue')\n",
    "axes[0].set_title('Daily Total Amount Over Time', fontsize=14)\n",
    "axes[0].set_ylabel('Total Amount ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add 7-day moving average\n",
    "daily_data['ma_7'] = daily_data['total_amount'].rolling(window=7).mean()\n",
    "axes[0].plot(daily_data['date'], daily_data['ma_7'], \n",
    "             linewidth=2, color='red', label='7-day MA')\n",
    "axes[0].legend()\n",
    "\n",
    "# Daily transaction count\n",
    "axes[1].plot(daily_data['date'], daily_data['transaction_count'], \n",
    "             linewidth=1, alpha=0.7, color='green')\n",
    "axes[1].set_title('Daily Transaction Count Over Time', fontsize=14)\n",
    "axes[1].set_ylabel('Number of Transactions')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add 7-day moving average for transactions\n",
    "daily_data['count_ma_7'] = daily_data['transaction_count'].rolling(window=7).mean()\n",
    "axes[1].plot(daily_data['date'], daily_data['count_ma_7'], \n",
    "             linewidth=2, color='red', label='7-day MA')\n",
    "axes[1].legend()\n",
    "\n",
    "# Daily average amount\n",
    "axes[2].plot(daily_data['date'], daily_data['avg_amount'], \n",
    "             linewidth=1, alpha=0.7, color='orange')\n",
    "axes[2].set_title('Daily Average Transaction Amount Over Time', fontsize=14)\n",
    "axes[2].set_ylabel('Average Amount ($)')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add 7-day moving average for average amount\n",
    "daily_data['avg_ma_7'] = daily_data['avg_amount'].rolling(window=7).mean()\n",
    "axes[2].plot(daily_data['date'], daily_data['avg_ma_7'], \n",
    "             linewidth=2, color='red', label='7-day MA')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time series statistics\n",
    "print(\"TIME SERIES STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Data points: {len(daily_data)}\")\n",
    "print(f\"Average daily amount: ${daily_data['total_amount'].mean():,.2f}\")\n",
    "print(f\"Standard deviation: ${daily_data['total_amount'].std():,.2f}\")\n",
    "print(f\"Coefficient of variation: {daily_data['total_amount'].std() / daily_data['total_amount'].mean():.2f}\")\n",
    "print(f\"Average daily transactions: {daily_data['transaction_count'].mean():.1f}\")\n",
    "print(f\"Max daily amount: ${daily_data['total_amount'].max():,.2f}\")\n",
    "print(f\"Min daily amount: ${daily_data['total_amount'].min():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801831a",
   "metadata": {},
   "source": [
    "## Trend Detection and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trends using the TrendAnalyzer\n",
    "amount_trend = trend_analyzer.detect_trend(daily_data, 'total_amount')\n",
    "count_trend = trend_analyzer.detect_trend(daily_data, 'transaction_count')\n",
    "\n",
    "print(\"TREND ANALYSIS RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Amount Trend: {amount_trend.trend_direction}\")\n",
    "print(f\"Amount Slope: {amount_trend.slope:.4f}\")\n",
    "print(f\"Amount RÂ²: {amount_trend.r_squared:.4f}\")\n",
    "print(f\"Amount P-value: {amount_trend.p_value:.6f}\")\n",
    "print(f\"Amount Trend Strength: {amount_trend.trend_strength}\")\n",
    "\n",
    "print(f\"\\nTransaction Count Trend: {count_trend.trend_direction}\")\n",
    "print(f\"Count Slope: {count_trend.slope:.4f}\")\n",
    "print(f\"Count RÂ²: {count_trend.r_squared:.4f}\")\n",
    "print(f\"Count P-value: {count_trend.p_value:.6f}\")\n",
    "print(f\"Count Trend Strength: {count_trend.trend_strength}\")\n",
    "\n",
    "# Visualize trends with regression lines\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Amount trend\n",
    "x_numeric = np.arange(len(daily_data))\n",
    "axes[0].scatter(daily_data['date'], daily_data['total_amount'], alpha=0.6, s=20)\n",
    "axes[0].plot(daily_data['date'], amount_trend.fitted_values, \n",
    "             color='red', linewidth=2, label=f'Trend (RÂ²={amount_trend.r_squared:.3f})')\n",
    "axes[0].set_title(f'Amount Trend: {amount_trend.trend_direction}')\n",
    "axes[0].set_ylabel('Total Amount ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Transaction count trend\n",
    "axes[1].scatter(daily_data['date'], daily_data['transaction_count'], alpha=0.6, s=20, color='green')\n",
    "axes[1].plot(daily_data['date'], count_trend.fitted_values, \n",
    "             color='red', linewidth=2, label=f'Trend (RÂ²={count_trend.r_squared:.3f})')\n",
    "axes[1].set_title(f'Transaction Count Trend: {count_trend.trend_direction}')\n",
    "axes[1].set_ylabel('Transaction Count')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Moving averages analysis\n",
    "ma_analysis = trend_analyzer.analyze_moving_averages(daily_data, 'total_amount', [7, 14, 30])\n",
    "\n",
    "print(\"\\nMOVING AVERAGES ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "for window, metrics in ma_analysis.items():\n",
    "    print(f\"\\n{window}-day Moving Average:\")\n",
    "    print(f\"  Current MA: ${metrics['current_ma']:.2f}\")\n",
    "    print(f\"  Previous MA: ${metrics['previous_ma']:.2f}\")\n",
    "    print(f\"  Change: ${metrics['ma_change']:.2f}\")\n",
    "    print(f\"  Trend: {metrics['ma_trend']}\")\n",
    "    print(f\"  Volatility: {metrics['volatility']:.2f}\")\n",
    "\n",
    "# Plot moving averages\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(daily_data['date'], daily_data['total_amount'], \n",
    "         alpha=0.3, label='Daily Amount', linewidth=1)\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, window in enumerate([7, 14, 30]):\n",
    "    ma = daily_data['total_amount'].rolling(window=window).mean()\n",
    "    plt.plot(daily_data['date'], ma, \n",
    "             color=colors[i], linewidth=2, label=f'{window}-day MA')\n",
    "\n",
    "plt.title('Moving Averages Comparison', fontsize=14)\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b12a52",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dec3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition if we have enough data\n",
    "if len(daily_data) >= 30:  # Need at least 30 days for meaningful decomposition\n",
    "    # Create a complete date range and fill missing dates\n",
    "    date_range = pd.date_range(start=daily_data['date'].min(), \n",
    "                              end=daily_data['date'].max(), \n",
    "                              freq='D')\n",
    "    \n",
    "    complete_data = pd.DataFrame({'date': date_range})\n",
    "    complete_data = complete_data.merge(daily_data, on='date', how='left')\n",
    "    complete_data['total_amount'] = complete_data['total_amount'].fillna(0)\n",
    "    \n",
    "    # Set date as index for decomposition\n",
    "    ts_data = complete_data.set_index('date')['total_amount']\n",
    "    \n",
    "    # Perform seasonal decomposition\n",
    "    try:\n",
    "        # Use additive decomposition with appropriate period\n",
    "        period = min(7, len(ts_data) // 3)  # Weekly seasonality or max possible\n",
    "        if period >= 3:\n",
    "            decomposition = seasonal_decompose(ts_data, model='additive', period=period)\n",
    "            \n",
    "            # Plot decomposition\n",
    "            fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "            \n",
    "            decomposition.observed.plot(ax=axes[0], title='Original Time Series')\n",
    "            decomposition.trend.plot(ax=axes[1], title='Trend Component')\n",
    "            decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')\n",
    "            decomposition.resid.plot(ax=axes[3], title='Residual Component')\n",
    "            \n",
    "            for ax in axes:\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Analyze decomposition components\n",
    "            print(\"SEASONAL DECOMPOSITION ANALYSIS\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Decomposition Period: {period} days\")\n",
    "            print(f\"Trend Strength: {1 - (np.var(decomposition.resid.dropna()) / np.var(decomposition.observed.dropna())):.3f}\")\n",
    "            print(f\"Seasonal Strength: {1 - (np.var(decomposition.resid.dropna()) / np.var(decomposition.observed.dropna() - decomposition.trend.dropna())):.3f}\")\n",
    "            \n",
    "            # Seasonal pattern analysis\n",
    "            seasonal_stats = decomposition.seasonal.groupby(decomposition.seasonal.index.dayofweek).mean()\n",
    "            day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "            \n",
    "            print(\"\\nSeasonal Pattern by Day of Week:\")\n",
    "            for i, day in enumerate(day_names):\n",
    "                if i in seasonal_stats.index:\n",
    "                    print(f\"  {day}: {seasonal_stats.iloc[i]:.2f}\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"Insufficient data for seasonal decomposition\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Seasonal decomposition failed: {e}\")\n",
    "        print(\"This is normal for datasets with insufficient seasonality\")\n",
    "else:\n",
    "    print(\"Insufficient data for seasonal decomposition (need at least 30 days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41c619",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12627828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies using the TrendAnalyzer\n",
    "anomalies = trend_analyzer.detect_anomalies(daily_data, 'total_amount')\n",
    "\n",
    "print(\"ANOMALY DETECTION RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total data points: {len(daily_data)}\")\n",
    "print(f\"Anomalies detected: {len(anomalies)}\")\n",
    "print(f\"Anomaly rate: {len(anomalies) / len(daily_data) * 100:.2f}%\")\n",
    "\n",
    "if len(anomalies) > 0:\n",
    "    print(\"\\nTop 5 Anomalies:\")\n",
    "    top_anomalies = anomalies.nlargest(5, 'amount')\n",
    "    for idx, row in top_anomalies.iterrows():\n",
    "        print(f\"  {row['date'].date()}: ${row['amount']:,.2f} (Score: {row['anomaly_score']:.3f})\")\n",
    "    \n",
    "    # Visualize anomalies\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot normal data\n",
    "    normal_data = daily_data[~daily_data.index.isin(anomalies.index)]\n",
    "    plt.scatter(normal_data['date'], normal_data['total_amount'], \n",
    "                alpha=0.6, s=30, color='blue', label='Normal')\n",
    "    \n",
    "    # Plot anomalies\n",
    "    plt.scatter(anomalies['date'], anomalies['amount'], \n",
    "                s=100, color='red', marker='x', label='Anomalies', linewidths=2)\n",
    "    \n",
    "    # Add trend line\n",
    "    plt.plot(daily_data['date'], daily_data['ma_7'], \n",
    "             color='green', linewidth=2, alpha=0.7, label='7-day MA')\n",
    "    \n",
    "    plt.title('Anomaly Detection in Daily Amounts', fontsize=14)\n",
    "    plt.ylabel('Total Amount ($)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Anomaly statistics\n",
    "    print(\"\\nANOMALY STATISTICS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Average anomaly amount: ${anomalies['amount'].mean():,.2f}\")\n",
    "    print(f\"Average normal amount: ${normal_data['total_amount'].mean():,.2f}\")\n",
    "    print(f\"Highest anomaly: ${anomalies['amount'].max():,.2f}\")\n",
    "    print(f\"Lowest anomaly: ${anomalies['amount'].min():,.2f}\")\n",
    "    \n",
    "    # Check if anomalies cluster on certain days\n",
    "    anomaly_days = anomalies['date'].dt.day_name().value_counts()\n",
    "    print(\"\\nAnomalies by Day of Week:\")\n",
    "    for day, count in anomaly_days.items():\n",
    "        print(f\"  {day}: {count}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nNo anomalies detected in the dataset\")\n",
    "    \n",
    "    # Still show the normal distribution\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(daily_data['date'], daily_data['total_amount'], alpha=0.6, s=30)\n",
    "    plt.plot(daily_data['date'], daily_data['ma_7'], color='red', linewidth=2, label='7-day MA')\n",
    "    plt.title('Daily Amounts (No Anomalies Detected)')\n",
    "    plt.ylabel('Total Amount ($)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(daily_data['total_amount'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Distribution of Daily Amounts')\n",
    "    plt.xlabel('Total Amount ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc213d79",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform forecasting using TrendAnalyzer\n",
    "forecast_days = min(30, len(daily_data) // 4)  # Forecast up to 30 days or 25% of data\n",
    "\n",
    "if len(daily_data) >= 10:  # Need at least 10 days for forecasting\n",
    "    forecast_result = trend_analyzer.forecast_trend(daily_data, 'total_amount', forecast_days)\n",
    "    \n",
    "    print(f\"FORECASTING RESULTS ({forecast_days} days ahead)\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Forecast method: {forecast_result.method}\")\n",
    "    print(f\"Model accuracy (MAE): ${forecast_result.accuracy_metrics['mae']:.2f}\")\n",
    "    print(f\"Model accuracy (RMSE): ${forecast_result.accuracy_metrics['rmse']:.2f}\")\n",
    "    print(f\"Confidence level: {forecast_result.confidence_level}%\")\n",
    "    \n",
    "    print(\"\\nForecast Summary:\")\n",
    "    print(f\"Average forecasted amount: ${forecast_result.forecast_values.mean():.2f}\")\n",
    "    print(f\"Total forecasted amount: ${forecast_result.forecast_values.sum():,.2f}\")\n",
    "    print(f\"Forecasted trend: {'Increasing' if forecast_result.forecast_values[-1] > forecast_result.forecast_values[0] else 'Decreasing'}\")\n",
    "    \n",
    "    # Visualize forecast\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Historical data\n",
    "    plt.plot(daily_data['date'], daily_data['total_amount'], \n",
    "             color='blue', linewidth=2, label='Historical Data')\n",
    "    \n",
    "    # Forecast\n",
    "    forecast_dates = pd.date_range(start=daily_data['date'].max() + pd.Timedelta(days=1), \n",
    "                                  periods=forecast_days, freq='D')\n",
    "    \n",
    "    plt.plot(forecast_dates, forecast_result.forecast_values, \n",
    "             color='red', linewidth=2, linestyle='--', label='Forecast')\n",
    "    \n",
    "    # Confidence intervals if available\n",
    "    if hasattr(forecast_result, 'confidence_intervals') and forecast_result.confidence_intervals is not None:\n",
    "        lower_bound = forecast_result.confidence_intervals['lower']\n",
    "        upper_bound = forecast_result.confidence_intervals['upper']\n",
    "        \n",
    "        plt.fill_between(forecast_dates, lower_bound, upper_bound, \n",
    "                        alpha=0.3, color='red', label='Confidence Interval')\n",
    "    \n",
    "    # Add vertical line at forecast start\n",
    "    plt.axvline(x=daily_data['date'].max(), color='gray', linestyle=':', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Financial Forecast - Next {forecast_days} Days', fontsize=14)\n",
    "    plt.ylabel('Total Amount ($)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Show forecast details\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'Date': forecast_dates,\n",
    "        'Forecasted_Amount': forecast_result.forecast_values\n",
    "    })\n",
    "    \n",
    "    print(\"\\nDetailed Forecast:\")\n",
    "    print(forecast_df.head(10).to_string(index=False))\n",
    "    \n",
    "    if len(forecast_df) > 10:\n",
    "        print(\"...\")\n",
    "        print(forecast_df.tail(5).to_string(index=False))\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for forecasting (need at least 10 days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bbf7d",
   "metadata": {},
   "source": [
    "## Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76845da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate various risk metrics\n",
    "print(\"RISK ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Volatility analysis\n",
    "daily_returns = daily_data['total_amount'].pct_change().dropna()\n",
    "volatility = daily_returns.std()\n",
    "annualized_volatility = volatility * np.sqrt(365)  # Annualized\n",
    "\n",
    "print(f\"Daily volatility: {volatility:.4f}\")\n",
    "print(f\"Annualized volatility: {annualized_volatility:.4f}\")\n",
    "\n",
    "# Value at Risk (VaR) - 95% confidence\n",
    "var_95 = np.percentile(daily_returns, 5)\n",
    "var_99 = np.percentile(daily_returns, 1)\n",
    "\n",
    "print(f\"\\nValue at Risk (95%): {var_95:.4f} ({var_95*100:.2f}%)\")\n",
    "print(f\"Value at Risk (99%): {var_99:.4f} ({var_99*100:.2f}%)\")\n",
    "\n",
    "# Maximum drawdown\n",
    "cumulative_returns = (1 + daily_returns).cumprod()\n",
    "peak = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - peak) / peak\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "print(f\"\\nMaximum drawdown: {max_drawdown:.4f} ({max_drawdown*100:.2f}%)\")\n",
    "\n",
    "# Downside deviation\n",
    "negative_returns = daily_returns[daily_returns < 0]\n",
    "downside_deviation = negative_returns.std()\n",
    "\n",
    "print(f\"Downside deviation: {downside_deviation:.4f}\")\n",
    "\n",
    "# Risk visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Daily returns distribution\n",
    "axes[0, 0].hist(daily_returns, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(var_95, color='red', linestyle='--', label=f'VaR 95%: {var_95:.3f}')\n",
    "axes[0, 0].axvline(var_99, color='darkred', linestyle='--', label=f'VaR 99%: {var_99:.3f}')\n",
    "axes[0, 0].set_title('Distribution of Daily Returns')\n",
    "axes[0, 0].set_xlabel('Daily Return')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative returns\n",
    "axes[0, 1].plot(daily_data['date'][1:], cumulative_returns, linewidth=2)\n",
    "axes[0, 1].set_title('Cumulative Returns')\n",
    "axes[0, 1].set_ylabel('Cumulative Return')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Drawdown chart\n",
    "axes[1, 0].fill_between(daily_data['date'][1:], drawdown, 0, alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('Drawdown Over Time')\n",
    "axes[1, 0].set_ylabel('Drawdown')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling volatility\n",
    "rolling_vol = daily_returns.rolling(window=7).std()\n",
    "axes[1, 1].plot(daily_data['date'][1:], rolling_vol, linewidth=2, color='orange')\n",
    "axes[1, 1].set_title('7-Day Rolling Volatility')\n",
    "axes[1, 1].set_ylabel('Volatility')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk assessment\n",
    "print(\"\\nRISK ASSESSMENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if annualized_volatility < 0.1:\n",
    "    risk_level = \"Low\"\n",
    "elif annualized_volatility < 0.2:\n",
    "    risk_level = \"Medium\"\n",
    "else:\n",
    "    risk_level = \"High\"\n",
    "\n",
    "print(f\"Overall risk level: {risk_level}\")\n",
    "print(f\"Volatility assessment: {'Stable' if volatility < 0.05 else 'Volatile' if volatility < 0.1 else 'Highly Volatile'}\")\n",
    "print(f\"Downside risk: {'Low' if abs(max_drawdown) < 0.05 else 'Medium' if abs(max_drawdown) < 0.15 else 'High'}\")\n",
    "\n",
    "# Risk recommendations\n",
    "print(\"\\nRISK MANAGEMENT RECOMMENDATIONS:\")\n",
    "if volatility > 0.1:\n",
    "    print(\"â€¢ High volatility detected - consider diversification strategies\")\n",
    "if abs(max_drawdown) > 0.1:\n",
    "    print(\"â€¢ Significant drawdowns observed - implement stop-loss mechanisms\")\n",
    "if len(negative_returns) / len(daily_returns) > 0.4:\n",
    "    print(\"â€¢ High frequency of negative returns - review operational efficiency\")\n",
    "if abs(var_95) > 0.05:\n",
    "    print(\"â€¢ High Value at Risk - maintain adequate cash reserves\")\n",
    "\n",
    "print(\"â€¢ Monitor risk metrics regularly\")\n",
    "print(\"â€¢ Maintain emergency fund for unexpected downturns\")\n",
    "print(\"â€¢ Consider hedging strategies for extreme scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44cdc5e",
   "metadata": {},
   "source": [
    "## Advanced Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc73b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced statistical analysis\n",
    "print(\"ADVANCED ANALYTICS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Autocorrelation analysis\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "autocorr = acf(daily_data['total_amount'], nlags=min(20, len(daily_data)//4))\n",
    "print(f\"First-order autocorrelation: {autocorr[1]:.4f}\")\n",
    "\n",
    "if abs(autocorr[1]) > 0.3:\n",
    "    print(\"Strong autocorrelation detected - data has memory\")\n",
    "elif abs(autocorr[1]) > 0.1:\n",
    "    print(\"Moderate autocorrelation detected\")\n",
    "else:\n",
    "    print(\"Low autocorrelation - data appears random\")\n",
    "\n",
    "# Stationarity test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adf_result = adfuller(daily_data['total_amount'].dropna())\n",
    "print(f\"\\nStationarity Test (ADF):\")\n",
    "print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"P-value: {adf_result[1]:.4f}\")\n",
    "print(f\"Data is {'stationary' if adf_result[1] < 0.05 else 'non-stationary'}\")\n",
    "\n",
    "# Periodicity detection\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "if len(daily_data) > 14:  # Need enough data for FFT\n",
    "    # Remove trend for better periodicity detection\n",
    "    detrended = daily_data['total_amount'] - daily_data['total_amount'].rolling(window=7).mean()\n",
    "    detrended = detrended.dropna()\n",
    "    \n",
    "    # Perform FFT\n",
    "    fft_values = fft(detrended)\n",
    "    frequencies = fftfreq(len(detrended))\n",
    "    \n",
    "    # Find dominant frequencies\n",
    "    power_spectrum = np.abs(fft_values)**2\n",
    "    dominant_freq_idx = np.argsort(power_spectrum)[-5:]  # Top 5 frequencies\n",
    "    \n",
    "    print(\"\\nPeriodicity Analysis:\")\n",
    "    for i, idx in enumerate(dominant_freq_idx[::-1]):\n",
    "        if frequencies[idx] != 0:  # Avoid division by zero\n",
    "            period = 1 / abs(frequencies[idx])\n",
    "            if 1 < period < len(detrended)/2:  # Reasonable periods only\n",
    "                print(f\"  Potential {period:.1f}-day cycle detected\")\n",
    "\n",
    "# Correlation with external factors (day of week, month)\n",
    "daily_data['day_of_week'] = daily_data['date'].dt.dayofweek\n",
    "daily_data['month'] = daily_data['date'].dt.month\n",
    "daily_data['is_weekend'] = daily_data['day_of_week'].isin([5, 6])\n",
    "\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "weekend_avg = daily_data[daily_data['is_weekend']]['total_amount'].mean()\n",
    "weekday_avg = daily_data[~daily_data['is_weekend']]['total_amount'].mean()\n",
    "\n",
    "print(f\"Weekend average: ${weekend_avg:.2f}\")\n",
    "print(f\"Weekday average: ${weekday_avg:.2f}\")\n",
    "print(f\"Weekend vs Weekday ratio: {weekend_avg/weekday_avg:.2f}\")\n",
    "\n",
    "# Month-over-month analysis\n",
    "monthly_avg = daily_data.groupby('month')['total_amount'].mean()\n",
    "print(f\"\\nBest performing month: {monthly_avg.idxmax()} (${monthly_avg.max():.2f})\")\n",
    "print(f\"Worst performing month: {monthly_avg.idxmin()} (${monthly_avg.min():.2f})\")\n",
    "\n",
    "# Visualization of advanced analytics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Autocorrelation plot\n",
    "lags = range(len(autocorr))\n",
    "axes[0, 0].bar(lags, autocorr)\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[0, 0].set_title('Autocorrelation Function')\n",
    "axes[0, 0].set_xlabel('Lag')\n",
    "axes[0, 0].set_ylabel('Autocorrelation')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Day of week analysis\n",
    "dow_avg = daily_data.groupby('day_of_week')['total_amount'].mean()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 1].bar(range(7), [dow_avg.get(i, 0) for i in range(7)])\n",
    "axes[0, 1].set_title('Average Amount by Day of Week')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Average Amount ($)')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(day_names)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly analysis\n",
    "axes[1, 0].bar(monthly_avg.index, monthly_avg.values)\n",
    "axes[1, 0].set_title('Average Amount by Month')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Amount ($)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling correlation with trend\n",
    "if len(daily_data) > 10:\n",
    "    x = np.arange(len(daily_data))\n",
    "    rolling_corr = pd.Series(daily_data['total_amount']).rolling(window=7).corr(pd.Series(x))\n",
    "    axes[1, 1].plot(daily_data['date'], rolling_corr, linewidth=2)\n",
    "    axes[1, 1].set_title('7-Day Rolling Correlation with Trend')\n",
    "    axes[1, 1].set_ylabel('Correlation')\n",
    "    axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72984d",
   "metadata": {},
   "source": [
    "## Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TREND ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ TREND ANALYSIS\")\n",
    "print(f\"   Overall Trend: {amount_trend.trend_direction} (Strength: {amount_trend.trend_strength})\")\n",
    "print(f\"   Trend Slope: {amount_trend.slope:.4f} per day\")\n",
    "print(f\"   R-squared: {amount_trend.r_squared:.4f}\")\n",
    "print(f\"   Statistical Significance: {'Yes' if amount_trend.p_value < 0.05 else 'No'} (p={amount_trend.p_value:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸ“Š VOLATILITY & RISK\")\n",
    "print(f\"   Daily Volatility: {volatility:.4f}\")\n",
    "print(f\"   Risk Level: {risk_level}\")\n",
    "print(f\"   Maximum Drawdown: {max_drawdown:.2f}%\")\n",
    "print(f\"   Value at Risk (95%): {var_95:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ” ANOMALIES\")\n",
    "print(f\"   Anomalies Detected: {len(anomalies)}\")\n",
    "print(f\"   Anomaly Rate: {len(anomalies) / len(daily_data) * 100:.2f}%\")\n",
    "if len(anomalies) > 0:\n",
    "    print(f\"   Largest Anomaly: ${anomalies['amount'].max():,.2f} on {anomalies.loc[anomalies['amount'].idxmax(), 'date'].date()}\")\n",
    "\n",
    "print(f\"\\nðŸ”® FORECASTING\")\n",
    "if len(daily_data) >= 10:\n",
    "    print(f\"   Forecast Period: {forecast_days} days\")\n",
    "    print(f\"   Forecast Method: {forecast_result.method}\")\n",
    "    print(f\"   Predicted Average: ${forecast_result.forecast_values.mean():.2f}\")\n",
    "    print(f\"   Forecast Accuracy (MAE): ${forecast_result.accuracy_metrics['mae']:.2f}\")\n",
    "else:\n",
    "    print(f\"   Insufficient data for forecasting\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ DATA CHARACTERISTICS\")\n",
    "print(f\"   Data Points: {len(daily_data)}\")\n",
    "print(f\"   Time Span: {(daily_data['date'].max() - daily_data['date'].min()).days} days\")\n",
    "print(f\"   Stationarity: {'Stationary' if adf_result[1] < 0.05 else 'Non-stationary'}\")\n",
    "print(f\"   Autocorrelation: {'Strong' if abs(autocorr[1]) > 0.3 else 'Moderate' if abs(autocorr[1]) > 0.1 else 'Weak'}\")\n",
    "\n",
    "print(f\"\\nðŸŒŸ KEY INSIGHTS\")\n",
    "\n",
    "# Trend insights\n",
    "if amount_trend.trend_direction == 'increasing':\n",
    "    print(f\"   âœ… Positive growth trend detected\")\n",
    "elif amount_trend.trend_direction == 'decreasing':\n",
    "    print(f\"   âš ï¸  Declining trend requires attention\")\n",
    "else:\n",
    "    print(f\"   âž¡ï¸  Stable trend with no significant change\")\n",
    "\n",
    "# Risk insights\n",
    "if risk_level == 'High':\n",
    "    print(f\"   ðŸ”´ High volatility - implement risk management\")\n",
    "elif risk_level == 'Medium':\n",
    "    print(f\"   ðŸŸ¡ Moderate risk - monitor closely\")\n",
    "else:\n",
    "    print(f\"   ðŸŸ¢ Low risk environment\")\n",
    "\n",
    "# Seasonal insights\n",
    "if not monthly_avg.empty:\n",
    "    seasonal_var = monthly_avg.std() / monthly_avg.mean()\n",
    "    if seasonal_var > 0.2:\n",
    "        print(f\"   ðŸ“… Strong seasonal patterns detected\")\n",
    "    else:\n",
    "        print(f\"   ðŸ“… Weak seasonal effects\")\n",
    "\n",
    "# Weekend effect\n",
    "weekend_effect = (weekend_avg - weekday_avg) / weekday_avg\n",
    "if abs(weekend_effect) > 0.1:\n",
    "    effect_dir = \"higher\" if weekend_effect > 0 else \"lower\"\n",
    "    print(f\"   ðŸ“† Weekend amounts are {abs(weekend_effect)*100:.1f}% {effect_dir} than weekdays\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDATIONS\")\n",
    "print(f\"   1. {'Maintain' if amount_trend.trend_direction == 'increasing' else 'Improve'} current trajectory\")\n",
    "print(f\"   2. {'Implement' if risk_level == 'High' else 'Monitor'} risk management strategies\")\n",
    "print(f\"   3. Use forecasting for {'short-term' if len(daily_data) < 30 else 'medium-term'} planning\")\n",
    "if len(anomalies) > 0:\n",
    "    print(f\"   4. Investigate anomalies for operational improvements\")\n",
    "print(f\"   5. Leverage seasonal patterns for strategic planning\")\n",
    "print(f\"   6. Regular monitoring of key trend indicators\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
